{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import f1_score\nimport xgboost as xgb\n\n\n\n\ndef inspect_data_structure(train_path, demo_path):\n    \"\"\"\n    Inspect the structure of both sensor and demographic data\n    \"\"\"\n    print(\"=== DATA STRUCTURE INSPECTION ===\")\n    \n    # Load and inspect sensor data\n    print(\"\\n1. SENSOR DATA STRUCTURE:\")\n    try:\n        train_df = pd.read_csv(train_path)\n        print(f\"Shape: {train_df.shape}\")\n        print(f\"Columns: {list(train_df.columns)}\")\n        print(f\"First few rows:\")\n        print(train_df.head())\n        \n        # Check for subject-related columns\n        subject_cols = [col for col in train_df.columns if 'subject' in col.lower()]\n        print(f\"Subject-related columns: {subject_cols}\")\n        \n    except Exception as e:\n        print(f\"Error loading sensor data: {e}\")\n    \n    # Load and inspect demographic data\n    print(\"\\n2. DEMOGRAPHIC DATA STRUCTURE:\")\n    try:\n        demo_df = pd.read_csv(demo_path)\n        print(f\"Shape: {demo_df.shape}\")\n        print(f\"Columns: {list(demo_df.columns)}\")\n        print(f\"First few rows:\")\n        print(demo_df.head())\n        \n    except Exception as e:\n        print(f\"Error loading demographic data: {e}\")\n\ndef fix_subject_column_mapping(df, demographic_data):\n    \"\"\"\n    Fix subject column mapping issues\n    \"\"\"\n    print(\"\\n=== FIXING SUBJECT COLUMN MAPPING ===\")\n    \n    # Find potential subject columns\n    potential_subject_cols = []\n    for col in df.columns:\n        if any(keyword in col.lower() for keyword in ['subject', 'user', 'participant', 'id']):\n            potential_subject_cols.append(col)\n    \n    print(f\"Potential subject columns: {potential_subject_cols}\")\n    \n    if not potential_subject_cols:\n        print(\"No obvious subject column found. Checking data patterns...\")\n        \n        # Look for columns with values that match demographic subjects\n        demo_subjects = set(demographic_data.index)\n        print(f\"Demographic subjects sample: {list(demo_subjects)[:10]}\")\n        \n        for col in df.columns:\n            if df[col].dtype in ['int64', 'object']:\n                col_values = set(df[col].unique())\n                overlap = len(col_values.intersection(demo_subjects))\n                if overlap > 0:\n                    print(f\"Column '{col}' has {overlap} matching values with demographics\")\n    \n    return potential_subject_cols\n\nclass EnhancedBFRBDetectionPipeline:\n    \"\"\"\n    Enhanced version with better subject column and label handling\n    \"\"\"\n    \n    def __init__(self, config=None):\n        self.config = config or self._get_default_config()\n        self.cnn_model = None\n        self.binary_classifier = None\n        self.multiclass_classifier = None\n        self.scalers = {}\n        self.label_encoders = {}\n        self.feature_cache = {}\n        self.demographic_data = None\n        self.subject_column = None\n        \n    def _get_default_config(self):\n        \"\"\"Optimized configuration with demographic support\"\"\"\n        return {\n            'sequence_length': 256,\n            'cnn_filters': [32, 64, 128],\n            'cnn_kernel_size': 5,\n            'cnn_feature_dim': 64,\n            'xgb_params': {\n                'n_estimators': 150,\n                'max_depth': 5,\n                'learning_rate': 0.15,\n                'subsample': 0.8,\n                'colsample_bytree': 0.8,\n                'random_state': 42,\n                'n_jobs': -1,\n                'tree_method': 'hist'\n            },\n            'cv_folds': 5,\n            'batch_size': 64,\n            'epochs': 30,\n            'early_stopping_patience': 5,\n            'use_demographics': True\n        }\n    \n    def load_demographic_data(self, train_path, test_path=None):\n        \"\"\"\n        Enhanced demographic data loading with better error handling\n        \"\"\"\n        print(\"Loading demographic data...\")\n        \n        try:\n            # Load train demographics\n            train_demo = pd.read_csv(train_path)\n            print(f\"Train demographics shape: {train_demo.shape}\")\n            print(f\"Train demographics columns: {list(train_demo.columns)}\")\n            \n            # Load test demographics if provided\n            if test_path:\n                test_demo = pd.read_csv(test_path)\n                print(f\"Test demographics shape: {test_demo.shape}\")\n                demo_data = pd.concat([train_demo, test_demo], axis=0)\n            else:\n                demo_data = train_demo.copy()\n            \n            # Identify subject column in demographics\n            if 'subject' in demo_data.columns:\n                subject_col = 'subject'\n            elif 'subject_id' in demo_data.columns:\n                subject_col = 'subject_id'\n            else:\n                # Try to find subject column\n                potential_cols = [col for col in demo_data.columns if 'subject' in col.lower()]\n                if potential_cols:\n                    subject_col = potential_cols[0]\n                    print(f\"Using '{subject_col}' as subject column\")\n                else:\n                    raise ValueError(\"No subject column found in demographic data\")\n            \n            # Convert categorical variables\n            categorical_cols = ['adult_child', 'sex', 'handedness']\n            for col in categorical_cols:\n                if col in demo_data.columns:\n                    demo_data[col] = demo_data[col].astype('category')\n            \n            # Normalize continuous variables\n            continuous_cols = ['age', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\n            existing_continuous = [col for col in continuous_cols if col in demo_data.columns]\n            \n            if existing_continuous:\n                demo_data[existing_continuous] = demo_data[existing_continuous].apply(\n                    lambda x: (x - x.mean()) / x.std()\n                )\n            \n            # Set subject as index\n            self.demographic_data = demo_data.set_index(subject_col)\n            print(f\"Loaded demographic data for {len(self.demographic_data)} subjects\")\n            \n        except Exception as e:\n            print(f\"Error loading demographic data: {e}\")\n            self.demographic_data = None\n    \n    def auto_detect_subject_column(self, df):\n        \"\"\"\n        Automatically detect the subject column in the sensor data\n        \"\"\"\n        if self.demographic_data is None:\n            return None\n        \n        demo_subjects = set(self.demographic_data.index)\n        \n        # Check common subject column names first\n        common_names = ['subject_id', 'subject', 'user_id', 'participant_id', 'id']\n        \n        for col_name in common_names:\n            if col_name in df.columns:\n                col_values = set(df[col_name].unique())\n                overlap = len(col_values.intersection(demo_subjects))\n                if overlap > 0:\n                    print(f\"Found subject column: '{col_name}' (matches {overlap} demographic subjects)\")\n                    return col_name\n        \n        # If no common names work, check all columns\n        for col in df.columns:\n            if df[col].dtype in ['int64', 'object', 'string']:\n                try:\n                    col_values = set(df[col].unique())\n                    overlap = len(col_values.intersection(demo_subjects))\n                    if overlap > len(demo_subjects) * 0.5:  # At least 50% overlap\n                        print(f\"Detected subject column: '{col}' (matches {overlap} demographic subjects)\")\n                        return col\n                except:\n                    continue\n        \n        print(\"Could not automatically detect subject column\")\n        return None\n    \n    def _add_demographic_features(self, df, subject_col=None):\n        \"\"\"\n        Enhanced demographic feature addition with auto-detection\n        \"\"\"\n        if not self.config['use_demographics'] or self.demographic_data is None:\n            return df\n        \n        # Auto-detect subject column if not provided\n        if subject_col is None:\n            if self.subject_column is None:\n                self.subject_column = self.auto_detect_subject_column(df)\n            subject_col = self.subject_column\n        \n        if subject_col is None or subject_col not in df.columns:\n            print(f\"Warning: Subject column not found. Available columns: {list(df.columns)}\")\n            return df\n        \n        print(f\"Merging demographic data using column: '{subject_col}'\")\n        \n        try:\n            # Merge demographic data\n            merged = df.merge(\n                self.demographic_data,\n                left_on=subject_col,\n                right_index=True,\n                how='left'\n            )\n            \n            # Check merge success\n            demo_cols = self.demographic_data.columns\n            merged_demo_cols = [col for col in demo_cols if col in merged.columns]\n            \n            if merged_demo_cols:\n                print(f\"Successfully merged {len(merged_demo_cols)} demographic features\")\n                \n                # Fill missing demographics with mode/median\n                for col in merged_demo_cols:\n                    missing_count = merged[col].isnull().sum()\n                    if missing_count > 0:\n                        print(f\"Filling {missing_count} missing values in '{col}'\")\n                        if merged[col].dtype == 'object' or merged[col].dtype.name == 'category':\n                            mode_val = merged[col].mode()\n                            if len(mode_val) > 0:\n                                merged[col] = merged[col].fillna(mode_val[0])\n                        else:\n                            merged[col] = merged[col].fillna(merged[col].median())\n            else:\n                print(\"Warning: No demographic features were successfully merged\")\n            \n            return merged\n        except Exception as e:\n            print(f\"Error merging demographic data: {e}\")\n            return df\n    \n    def preprocess_data(self, df, is_training=True):\n        \"\"\"\n        Enhanced preprocessing with better subject column handling\n        Returns the processed dataframe\n        \"\"\"\n        print(\"Stage 1: Data Preprocessing...\")\n        print(f\"Input data shape: {df.shape}\")\n        print(f\"Input columns: {list(df.columns)}\")\n        \n        # Add demographic features if available\n        df = self._add_demographic_features(df)\n        \n        # Identify sensor columns\n        imu_cols = [col for col in df.columns if 'imu' in col.lower() or 'acc_' in col.lower() or 'rot_' in col.lower()]\n        temp_cols = [col for col in df.columns if 'temp' in col.lower() or 'thermopile' in col.lower() or 'thm_' in col.lower()]\n        tof_cols = [col for col in df.columns if 'tof' in col.lower() or 'distance' in col.lower()]\n        \n        print(f\"Found {len(imu_cols)} IMU columns, {len(temp_cols)} temperature columns, {len(tof_cols)} ToF columns\")\n        \n        processed_df = df.copy()\n        \n        # IMU preprocessing\n        for col in imu_cols:\n            if col in processed_df.columns:\n                processed_df[col] = processed_df[col].fillna(method='ffill').fillna(method='bfill')\n        \n        # Temperature preprocessing\n        for col in temp_cols:\n            if col in processed_df.columns:\n                median_val = processed_df[col].median()\n                processed_df[col] = processed_df[col].fillna(median_val)\n        \n        # Time-of-Flight preprocessing\n        for col in tof_cols:\n            if col in processed_df.columns:\n                processed_df[col] = processed_df[col].replace(-1, np.nan)\n                median_val = processed_df[col].median()\n                processed_df[col] = processed_df[col].fillna(median_val)\n        \n        # Remove outliers (only for numeric columns, excluding ID columns)\n        numeric_cols = processed_df.select_dtypes(include=[np.number]).columns\n        id_cols = [col for col in numeric_cols if any(keyword in col.lower() \n                  for keyword in ['subject', 'session', 'gesture', 'id'])]\n        \n        for col in numeric_cols:\n            if col not in id_cols:\n                Q1 = processed_df[col].quantile(0.25)\n                Q3 = processed_df[col].quantile(0.75)\n                IQR = Q3 - Q1\n                if IQR > 0:  # Avoid division by zero\n                    lower_bound = Q1 - 1.5 * IQR\n                    upper_bound = Q3 + 1.5 * IQR\n                    processed_df[col] = processed_df[col].clip(lower=lower_bound, upper=upper_bound)\n        \n        return processed_df\n    \n    def _extract_sequence_features(self, sequence):\n        \"\"\"\n        Extract comprehensive features from a sequence\n        \"\"\"\n        features = []\n        \n        # Statistical features\n        features.extend([\n            np.mean(sequence, axis=0).flatten(),\n            np.std(sequence, axis=0).flatten(),\n            np.min(sequence, axis=0).flatten(),\n            np.max(sequence, axis=0).flatten(),\n            np.median(sequence, axis=0).flatten()\n        ])\n        \n        # Flatten all features\n        features = np.concatenate([f.flatten() if hasattr(f, 'flatten') else [f] for f in features])\n        \n        return features.tolist()\n    \n    def extract_features(self, df, sequence_col=None, label_col=None):\n        \"\"\"\n        Enhanced feature extraction that handles both sequence and non-sequence data\n        \"\"\"\n        print(\"Stage 2: Feature Engineering...\")\n        \n        features = []\n        labels = []\n        subjects = []\n        \n        # If no sequence column specified, use all numeric features\n        if sequence_col is None or sequence_col not in df.columns:\n            print(\"No sequence column found - using all numeric features\")\n            numeric_cols = df.select_dtypes(include=[np.number]).columns\n            exclude_cols = ['id', 'subject_id', 'session_id', 'gesture_id']\n            feature_cols = [col for col in numeric_cols if col not in exclude_cols]\n            \n            for idx, row in df.iterrows():\n                try:\n                    feature_vector = [row[col] for col in feature_cols]\n                    \n                    # Add demographic features if available\n                    if self.subject_column and self.subject_column in row and self.demographic_data is not None:\n                        subject = row[self.subject_column]\n                        if subject in self.demographic_data.index:\n                            demo_features = self.demographic_data.loc[subject].values\n                            feature_vector.extend(demo_features)\n                    \n                    features.append(feature_vector)\n                    \n                    if label_col and label_col in row:\n                        labels.append(row[label_col])\n                    \n                    if self.subject_column and self.subject_column in row:\n                        subjects.append(row[self.subject_column])\n                        \n                except Exception as e:\n                    print(f\"Error processing row {idx}: {e}\")\n                    continue\n        else:\n            # Original sequence handling code\n            for idx, row in df.iterrows():\n                try:\n                    sequence = np.array(row[sequence_col])\n                    if len(sequence.shape) == 1:\n                        sequence = sequence.reshape(-1, 1)\n                    \n                    # Pad/truncate sequence\n                    seq_len = self.config['sequence_length']\n                    if sequence.shape[0] > seq_len:\n                        sequence = sequence[:seq_len]\n                    elif sequence.shape[0] < seq_len:\n                        padding = np.zeros((seq_len - sequence.shape[0], sequence.shape[1]))\n                        sequence = np.vstack([sequence, padding])\n                    \n                    feature_vector = self._extract_sequence_features(sequence)\n                    \n                    # Add demographic features\n                    if self.subject_column and self.subject_column in row and self.demographic_data is not None:\n                        subject = row[self.subject_column]\n                        if subject in self.demographic_data.index:\n                            demo_features = self.demographic_data.loc[subject].values\n                            feature_vector.extend(demo_features)\n                    \n                    features.append(feature_vector)\n                    \n                    if label_col and label_col in row:\n                        labels.append(row[label_col])\n                    \n                    if self.subject_column and self.subject_column in row:\n                        subjects.append(row[self.subject_column])\n                        \n                except Exception as e:\n                    print(f\"Error processing row {idx}: {e}\")\n                    continue\n        \n        features_df = pd.DataFrame(features)\n        result = {'features': features_df}\n        \n        if labels:\n            result['labels'] = np.array(labels)\n        if subjects:\n            result['subjects'] = np.array(subjects)\n            \n        print(f\"Feature extraction complete. Features shape: {features_df.shape}\")\n        return result\n    \n    def train(self, X, y, subjects=None):\n        \"\"\"\n        Train the complete pipeline with proper label encoding\n        \"\"\"\n        print(\"Stage 3: Model Training...\")\n        \n        # Prepare data\n        X = np.array(X)\n        y = np.array(y)\n        \n        # Scale features\n        self.scalers['features'] = StandardScaler()\n        X_scaled = self.scalers['features'].fit_transform(X)\n        \n        # First encode all labels (convert strings to numeric)\n        self.label_encoders['main'] = LabelEncoder()\n        y_encoded = self.label_encoders['main'].fit_transform(y)\n        \n        # Create binary labels (1 for any BFRB, 0 for no BFRB)\n        # Assuming class 0 is \"no BFRB\" - adjust if needed\n        self.label_encoders['binary'] = LabelEncoder()\n        y_binary = (y_encoded > 0).astype(int)  # Binary: BFRB vs no BFRB\n        \n        # Train binary classifier\n        print(\"Training binary classifier...\")\n        self.binary_classifier = xgb.XGBClassifier(**self.config['xgb_params'])\n        self.binary_classifier.fit(X_scaled, y_binary)\n        \n        # Train multiclass classifier if needed\n        unique_classes = len(np.unique(y_encoded))\n        if unique_classes > 2:\n            print(f\"Training multiclass classifier for {unique_classes} classes...\")\n            self.multiclass_classifier = xgb.XGBClassifier(**self.config['xgb_params'])\n            self.multiclass_classifier.fit(X_scaled, y_encoded)\n        \n        # Evaluate\n        binary_pred = self.binary_classifier.predict(X_scaled)\n        binary_f1 = f1_score(y_binary, binary_pred, average='weighted')\n        \n        results = {\n            'binary_f1': binary_f1,\n            'feature_importance': self.binary_classifier.feature_importances_\n        }\n        \n        if hasattr(self, 'multiclass_classifier'):\n            multi_pred = self.multiclass_classifier.predict(X_scaled)\n            multi_f1 = f1_score(y_encoded, multi_pred, average='weighted')\n            results['multiclass_f1'] = multi_f1\n        \n        print(f\"Training complete. Binary F1: {binary_f1:.4f}\")\n        return results\n    \n    def predict(self, X):\n        \"\"\"\n        Make predictions on new data\n        \"\"\"\n        print(\"Making predictions...\")\n        \n        X = np.array(X)\n        X_scaled = self.scalers['features'].transform(X)\n        \n        # Get binary predictions first\n        binary_pred = self.binary_classifier.predict(X_scaled)\n        \n        if hasattr(self, 'multiclass_classifier'):\n            # Get multiclass predictions\n            multi_pred = self.multiclass_classifier.predict(X_scaled)\n            # Convert back to original labels\n            multi_pred = self.label_encoders['main'].inverse_transform(multi_pred)\n            # Use multiclass predictions where binary predicts BFRB\n            final_pred = np.where(binary_pred == 1, multi_pred, self.label_encoders['main'].classes_[0])\n        else:\n            final_pred = self.label_encoders['main'].inverse_transform(binary_pred)\n        \n        return final_pred\n\n\ndef debug_and_run_pipeline():\n    \"\"\"\n    Debug version of the pipeline execution with both train and test data\n    \"\"\"\n    print(\"=== BFRB PIPELINE DEBUGGING ===\")\n    \n    # File paths (update these to your actual paths)\n    train_sensor_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv'\n    test_sensor_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv'\n    train_demo_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv'\n    test_demo_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n    \n    # Step 1: Inspect data structure for both train and test\n    try:\n        print(\"Inspecting TRAIN sensor data:\")\n        inspect_data_structure(train_sensor_path, train_demo_path)\n        \n        print(\"\\nInspecting TEST sensor data:\")\n        inspect_data_structure(test_sensor_path, test_demo_path)\n        \n    except Exception as e:\n        print(f\"Could not inspect data structure: {e}\")\n    \n    # Step 2: Initialize enhanced pipeline\n    pipeline = EnhancedBFRBDetectionPipeline()\n    \n    # Step 3: Load demographic data (both train and test)\n    pipeline.load_demographic_data(train_demo_path, test_demo_path)\n    \n    # Step 4: Load and process sensor data\n    try:\n        print(\"\\n=== LOADING TRAIN SENSOR DATA ===\")\n        train_df = pd.read_csv(train_sensor_path)\n        print(f\"Train sensor data shape: {train_df.shape}\")\n        \n        print(\"\\n=== LOADING TEST SENSOR DATA ===\")\n        test_df = pd.read_csv(test_sensor_path)\n        print(f\"Test sensor data shape: {test_df.shape}\")\n        \n        # Step 5: Fix subject column mapping (check both datasets)\n        if pipeline.demographic_data is not None:\n            print(\"\\nChecking subject column mapping for TRAIN data:\")\n            train_potential_cols = fix_subject_column_mapping(train_df, pipeline.demographic_data)\n            \n            print(\"\\nChecking subject column mapping for TEST data:\")\n            test_potential_cols = fix_subject_column_mapping(test_df, pipeline.demographic_data)\n        \n        # Step 6: Preprocess both datasets\n        print(\"\\n=== PREPROCESSING TRAIN DATA ===\")\n        train_processed = pipeline.preprocess_data(train_df, is_training=True)\n        \n        print(\"\\n=== PREPROCESSING TEST DATA ===\")\n        test_processed = pipeline.preprocess_data(test_df, is_training=False)\n        \n        print(f\"\\nFinal train processed data shape: {train_processed.shape}\")\n        print(f\"Final test processed data shape: {test_processed.shape}\")\n        print(\"Pipeline setup complete!\")\n        \n        return pipeline, train_processed, test_processed\n        \n    except Exception as e:\n        print(f\"Error in pipeline execution: {e}\")\n        return pipeline, None, None\n\ndef complete_end_to_end_pipeline():\n    \"\"\"\n    Complete end-to-end pipeline from data loading to Kaggle submission\n    \"\"\"\n    print(\"🚀 STARTING COMPLETE BFRB DETECTION PIPELINE\")\n    print(\"=\" * 60)\n    \n    # File paths \n    train_sensor_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv'\n    test_sensor_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv'\n    train_demo_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv'\n    test_demo_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n    \n    try:\n        # STEP 1: Initialize pipeline\n        print(\"\\n📋 STEP 1: Initializing Pipeline...\")\n        pipeline = EnhancedBFRBDetectionPipeline()\n        \n        # STEP 2: Load demographic data\n        print(\"\\n👥 STEP 2: Loading Demographic Data...\")\n        pipeline.load_demographic_data(train_demo_path, test_demo_path)\n        \n        # STEP 3: Load and preprocess sensor data\n        print(\"\\n📊 STEP 3: Loading and Preprocessing Sensor Data...\")\n        train_df = pd.read_csv(train_sensor_path)\n        test_df = pd.read_csv(test_sensor_path)\n        \n        print(f\"Original train data: {train_df.shape}\")\n        print(f\"Original test data: {test_df.shape}\")\n        \n        train_processed = pipeline.preprocess_data(train_df, is_training=True)\n        test_processed = pipeline.preprocess_data(test_df, is_training=False)\n        \n        # STEP 4: Extract features\n        print(\"\\n🔧 STEP 4: Feature Engineering...\")\n        \n        # Determine the correct label column - use 'behavior' as primary\n        label_col = 'behavior' if 'behavior' in train_processed.columns else None\n        if label_col is None:\n            for col in ['label', 'target', 'y', 'class']:\n                if col in train_processed.columns:\n                    label_col = col\n                    break\n\n        if label_col is None:\n            print(\"❌ No label column found in training data!\")\n            return None\n        \n        # No sequence column - using all numeric features\n        sequence_col = None\n        \n        print(f\"Using label column: {label_col}\")\n        print(f\"Available columns: {list(train_processed.columns)}\")\n        \n        # Extract features from training data\n        train_data = pipeline.extract_features(train_processed, sequence_col, label_col)\n        \n        # Extract features from test data\n        test_data = pipeline.extract_features(test_processed, sequence_col)\n        \n        # STEP 5: Train the model\n        print(\"\\n🎯 STEP 5: Training Model...\")\n        if 'labels' in train_data:\n            results = pipeline.train(\n                train_data['features'],\n                train_data['labels'],\n                train_data.get('subjects', None)\n            )\n            \n            print(f\"✅ Training Results:\")\n            for key, value in results.items():\n                if key != 'feature_importance':\n                    print(f\"   {key}: {value}\")\n        else:\n            print(\"❌ No labels found in training data!\")\n            return None\n        \n        # STEP 6: Make predictions\n        print(\"\\n🔮 STEP 6: Making Predictions...\")\n        predictions = pipeline.predict(test_data['features'])\n        \n        # STEP 7: Create submission\n        print(\"\\n📤 STEP 7: Creating Submission File...\")\n        \n        # Find ID column in test data - use 'row_id' as primary\n        id_col = 'row_id' if 'row_id' in test_df.columns else None\n        if id_col is None:\n            for col in ['id', 'ID', 'test_id', 'sample_id']:\n                if col in test_df.columns:\n                    id_col = col\n                    break\n        \n        if id_col:\n            submission = pd.DataFrame({\n                id_col: test_df[id_col],\n                'prediction': predictions\n            })\n            submission.to_csv('bfrb_submission.csv', index=False)\n            print(f\"✅ Submission saved as 'bfrb_submission.csv'\")\n            print(f\"   Shape: {submission.shape}\")\n            if isinstance(predictions[0], str):\n                unique_preds, counts = np.unique(predictions, return_counts=True)\n                print(f\"Prediction distribution:\\n{dict(zip(unique_preds, counts))}\")\n            else:\n                print(f\"Prediction distribution: {np.bincount(predictions)}\")\n            \n            # Save models and scaler\n            print(\"\\n💾 Saving trained models and scaler...\")\n            pipeline.binary_classifier.save_model('binary_model.json')\n            pipeline.multiclass_classifier.save_model('multiclass_model.json')\n            joblib.dump(pipeline.scalers['features'], 'scaler.pkl')\n            print(\"✅ Models and scaler saved successfully\")\n            \n        else:\n            print(\"❌ No ID column found for submission\")\n            \n        print(\"\\n🎉 PIPELINE COMPLETED SUCCESSFULLY!\")\n        print(\"=\" * 60)\n        \n        return pipeline, results, predictions, submission if id_col else None\n        \n    except Exception as e:\n        print(f\"\\n❌ ERROR in pipeline: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None        \n\n\n\n\ndef quick_data_exploration():\n    \"\"\"\n    Quick exploration of the data structure to understand what we're working with\n    \"\"\"\n    print(\"🔍 QUICK DATA EXPLORATION\")\n    print(\"=\" * 40)\n    \n    try:\n        # Load data\n        train_df = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv')\n        test_df = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv')\n        train_demo = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv')\n        \n        print(f\"\\n📊 TRAIN DATA:\")\n        print(f\"   Shape: {train_df.shape}\")\n        print(f\"   Columns: {list(train_df.columns)}\")\n        print(f\"   Sample data:\")\n        print(train_df.head(2))\n        \n        print(f\"\\n📊 TEST DATA:\")\n        print(f\"   Shape: {test_df.shape}\")\n        print(f\"   Columns: {list(test_df.columns)}\")\n        \n        print(f\"\\n👥 DEMOGRAPHIC DATA:\")\n        print(f\"   Shape: {train_demo.shape}\")\n        print(f\"   Columns: {list(train_demo.columns)}\")\n        print(f\"   Sample data:\")\n        print(train_demo.head(2))\n        \n        return train_df, test_df, train_demo\n        \n    except Exception as e:\n        print(f\"Error in data exploration: {e}\")\n        return None, None, None\n\n\nif __name__ == \"__main__\":\n    # OPTION 1: Quick data exploration first (recommended)\n    print(\"🔍 Starting with data exploration...\")\n    train_df, test_df, demo_df = quick_data_exploration()\n    \n    if train_df is not None:\n        print(\"\\n\" + \"=\"*60)\n        # OPTION 2: Run the complete end-to-end pipeline\n        result = complete_end_to_end_pipeline()\n        \n        if result:\n            pipeline, training_results, predictions, submission = result\n            print(f\"\\n✅ All done! Check your 'bfrb_submission.csv' file\")\n        else:\n            print(\"\\n❌ Pipeline failed. Check the errors above.\")\n    else:\n        print(\"\\n❌ Could not load data. Check your file paths.\")\n    \n    # OPTION 3: If you want to debug step by step, uncomment this:\n    # pipeline, train_processed, test_processed = debug_and_run_pipeline()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T13:07:46.413854Z","iopub.execute_input":"2025-08-06T13:07:46.414194Z","iopub.status.idle":"2025-08-06T13:21:50.437065Z","shell.execute_reply.started":"2025-08-06T13:07:46.414171Z","shell.execute_reply":"2025-08-06T13:21:50.436291Z"}},"outputs":[{"name":"stdout","text":"🔍 Starting with data exploration...\n🔍 QUICK DATA EXPLORATION\n========================================\n\n📊 TRAIN DATA:\n   Shape: (574945, 341)\n   Columns: ['row_id', 'sequence_type', 'sequence_id', 'sequence_counter', 'subject', 'orientation', 'behavior', 'phase', 'gesture', 'acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\n   Sample data:\n              row_id sequence_type sequence_id  sequence_counter      subject  \\\n0  SEQ_000007_000000        Target  SEQ_000007                 0  SUBJ_059520   \n1  SEQ_000007_000001        Target  SEQ_000007                 1  SUBJ_059520   \n\n                       orientation                                   behavior  \\\n0  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n1  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n\n        phase             gesture     acc_x  ...  tof_5_v54  tof_5_v55  \\\n0  Transition  Cheek - pinch skin  6.683594  ...       -1.0       -1.0   \n1  Transition  Cheek - pinch skin  6.949219  ...       -1.0       -1.0   \n\n   tof_5_v56  tof_5_v57  tof_5_v58  tof_5_v59  tof_5_v60  tof_5_v61  \\\n0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n\n   tof_5_v62  tof_5_v63  \n0       -1.0       -1.0  \n1       -1.0       -1.0  \n\n[2 rows x 341 columns]\n\n📊 TEST DATA:\n   Shape: (107, 336)\n   Columns: ['row_id', 'sequence_id', 'sequence_counter', 'subject', 'acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\n\n👥 DEMOGRAPHIC DATA:\n   Shape: (81, 8)\n   Columns: ['subject', 'adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\n   Sample data:\n       subject  adult_child  age  sex  handedness  height_cm  \\\n0  SUBJ_000206            1   41    1           1      172.0   \n1  SUBJ_001430            0   11    0           1      167.0   \n\n   shoulder_to_wrist_cm  elbow_to_wrist_cm  \n0                    50               25.0  \n1                    51               27.0  \n\n============================================================\n🚀 STARTING COMPLETE BFRB DETECTION PIPELINE\n============================================================\n\n📋 STEP 1: Initializing Pipeline...\n\n👥 STEP 2: Loading Demographic Data...\nLoading demographic data...\nTrain demographics shape: (81, 8)\nTrain demographics columns: ['subject', 'adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\nTest demographics shape: (2, 8)\nLoaded demographic data for 83 subjects\n\n📊 STEP 3: Loading and Preprocessing Sensor Data...\nOriginal train data: (574945, 341)\nOriginal test data: (107, 336)\nStage 1: Data Preprocessing...\nInput data shape: (574945, 341)\nInput columns: ['row_id', 'sequence_type', 'sequence_id', 'sequence_counter', 'subject', 'orientation', 'behavior', 'phase', 'gesture', 'acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\nFound subject column: 'subject' (matches 81 demographic subjects)\nMerging demographic data using column: 'subject'\nSuccessfully merged 7 demographic features\nFound 7 IMU columns, 5 temperature columns, 320 ToF columns\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3958839433.py:284: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  processed_df[col] = processed_df[col].fillna(method='ffill').fillna(method='bfill')\n","output_type":"stream"},{"name":"stdout","text":"Stage 1: Data Preprocessing...\nInput data shape: (107, 336)\nInput columns: ['row_id', 'sequence_id', 'sequence_counter', 'subject', 'acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\nMerging demographic data using column: 'subject'\nSuccessfully merged 7 demographic features\nFound 7 IMU columns, 5 temperature columns, 320 ToF columns\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3958839433.py:284: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  processed_df[col] = processed_df[col].fillna(method='ffill').fillna(method='bfill')\n","output_type":"stream"},{"name":"stdout","text":"\n🔧 STEP 4: Feature Engineering...\nUsing label column: behavior\nAvailable columns: ['row_id', 'sequence_type', 'sequence_id', 'sequence_counter', 'subject', 'orientation', 'behavior', 'phase', 'gesture', 'acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63', 'adult_child', 'age', 'sex', 'handedness', 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\nStage 2: Feature Engineering...\nNo sequence column found - using all numeric features\nFeature extraction complete. Features shape: (574945, 344)\nStage 2: Feature Engineering...\nNo sequence column found - using all numeric features\nFeature extraction complete. Features shape: (107, 344)\n\n🎯 STEP 5: Training Model...\nStage 3: Model Training...\nTraining binary classifier...\nTraining multiclass classifier for 4 classes...\nTraining complete. Binary F1: 0.8570\n✅ Training Results:\n   binary_f1: 0.8569755879887645\n   multiclass_f1: 0.771002684994614\n\n🔮 STEP 6: Making Predictions...\nMaking predictions...\n\n📤 STEP 7: Creating Submission File...\n✅ Submission saved as 'bfrb_submission.csv'\n   Shape: (107, 2)\nPrediction distribution:\n{'Hand at target location': 22, 'Moves hand to target location': 3, 'Performs gesture': 58, 'Relaxes and moves hand to target location': 24}\n\n💾 Saving trained models and scaler...\n✅ Models and scaler saved successfully\n\n🎉 PIPELINE COMPLETED SUCCESSFULLY!\n============================================================\n\n✅ All done! Check your 'bfrb_submission.csv' file\n","output_type":"stream"}],"execution_count":7}]}